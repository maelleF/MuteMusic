{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66d0568d-0605-4692-b73c-8f65ace7e515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a1f2a8-a7f8-4d1a-8837-8c936041c682",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/maellef/git/MuteMusic/data/StimuliFinal/long'\n",
    "silences_nb = [3,4]\n",
    "min=3\n",
    "max=6\n",
    "\n",
    "rng = np.random.default_rng(2022)\n",
    "\n",
    "for category in os.listdir(path):\n",
    "    for file in os.listdir(os.path.join(path, category)):\n",
    "        name, ext = os.path.splitext(file)\n",
    "        if ext == '.wav':\n",
    "            path_wav=os.path.join(path, category, file)\n",
    "            wav, sr = librosa.load(path_wav, sr=None)\n",
    "            if len(wav)/sr > 65 or len(wav)/sr < 46:\n",
    "                possible_nb_silences = [x for x in silences_nb if (len(wav)*0.25 >= x*min*sr) and (len(wav)*0.25 <= x*max*sr)]\n",
    "                silence = rng.choice(possible_nb_silences)\n",
    "                a = int(len(wav)*0.25)\n",
    "                \n",
    "                cond=True\n",
    "                while cond:\n",
    "                    test = [rng.choice(a) for _ in range(silence-1)]\n",
    "                    test.append(0)\n",
    "                    test.append(int(len(wav)*0.25))\n",
    "                    test.sort()\n",
    "                    durations=[]\n",
    "                    for i in range(len(test)-1):\n",
    "                        duration = test[i+1]-test[i]\n",
    "                        if not (duration/sr > min and duration/sr < max):\n",
    "                            break\n",
    "                        else :\n",
    "                            durations.append(duration/sr)\n",
    "                            cond=False\n",
    "\n",
    "                print(name, sr, len(wav)/sr, (len(wav)*0.25)/sr, possible_nb_silences, silence, durations)\n",
    "                    \n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e511000-23b5-4ce4-a36f-57ae1b420565",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav, sr = librosa.load(path_wav, sr=None)\n",
    "\n",
    "for dirpath, dirnames, files in os.walk(path):\n",
    "    min_filename = ''\n",
    "    wav_min = 3000000\n",
    "    if len(files) > 0:\n",
    "        for filename in files:\n",
    "            name, ext = os.path.splitext(filename)\n",
    "            if ext == '.wav':\n",
    "                wav, wav_sr = librosa.load(os.path.join(dirpath, filename), sr=None)\n",
    "                if len(wav) < wav_min:\n",
    "                    wav_min = len(wav)\n",
    "                    min_filename = filename\n",
    "                if wav_sr != sr :\n",
    "                    print(f'sr = {wav_sr} for {filename}')\n",
    "                else :\n",
    "                    pass\n",
    "        print(f'check finished for {dirpath}, min duration is {wav_min/wav_sr}s for {min_filename}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc448aec-7b5b-475f-945c-fa1c118cf026",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the sizes and timestamps of all silences to be inserted into track (based on parameters)\n",
    "def define_silences_timestamps(start_wav, end_wav, total_wav, sr,\n",
    "                               percent_silence, silences_nb,\n",
    "                               silence_min, silence_max, silence_interval_min):\n",
    "    rng = np.random.default_rng(2023)\n",
    "    total_silence = int(total_wav*percent_silence)\n",
    "    possible_nb_silences = [x for x in silences_nb if (total_silence >= x*silence_min*sr) and (total_silence <= x*silence_max*sr)]\n",
    "    silence_nb = int(rng.choice(possible_nb_silences))\n",
    "    print(f'aaaaaaaaa{silence_nb}')\n",
    "    #silences_length = [0]*silence_nb\n",
    "\n",
    "    #---------------------------------------------------------------------------------------------------------\n",
    "    cond=True\n",
    "    while cond:\n",
    "        silences_lim = rng.choice(total_silence, size=silence_nb)\n",
    "        silences_lim = np.concatenate((silences_lim, [0, total_silence]))\n",
    "        silences_lim = np.sort(silences_lim)\n",
    "        silences_length=[]\n",
    "        for i in range(len(silences_lim)-1):\n",
    "            duration = silences_lim[i+1]-silences_lim[i]\n",
    "            if not (duration/sr > silence_min and duration/sr < silence_max):\n",
    "                break\n",
    "            else :\n",
    "                silences_length.append(duration)\n",
    "                cond=False\n",
    "    print(f'b{silences_length/sr}')\n",
    "    \n",
    "    #while sum(silences_length) != total_silence:\n",
    "    #    silences_length = rng.integers(low=silence_min*sr, high=silence_max*sr, size = silence_nb, endpoint=True)\n",
    "    #-----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    \n",
    "    silences_timestamps=[]\n",
    "    for silence_duration in silences_length:\n",
    "        while True:\n",
    "            start_silence = rng.integers(low=start_wav, high=end_wav-silence_duration, size = 1, endpoint=True)\n",
    "            stop_silence = start_silence+silence_duration\n",
    "            if len(silences_timestamps) > 0:\n",
    "                correct_timestamp = []\n",
    "                for (_, start, stop) in silences_timestamps: \n",
    "                    start_before_silence = stop_silence < (start - sr*silence_interval_min) \n",
    "                    start_after_silence = start_silence > (stop + sr*silence_interval_min)\n",
    "                    correct_timestamp.append(start_before_silence + start_after_silence)\n",
    "                    \n",
    "                if np.prod(correct_timestamp):\n",
    "                    silences_timestamps.append((silence_duration, start_silence[0], stop_silence[0]))\n",
    "                    break\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                silences_timestamps.append((silence_duration, start_silence[0], stop_silence[0]))\n",
    "                break\n",
    "                \n",
    "    #for silence_duration, start, stop in silences_timestamps:\n",
    "        #print(silence_duration/sr, start/sr, stop/sr)\n",
    "    \n",
    "    return silences_timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0dafc26-f7f5-482c-8ffc-fb795d637170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_silences(wav, sr,\n",
    "                    silences_timestamps,\n",
    "                    fading_duration):\n",
    "    #insert fading\n",
    "    fadein = np.linspace(0,1,np.int32(fading_duration*sr))\n",
    "    fadeout = np.linspace(1,0,np.int32(fading_duration*sr))\n",
    "    wav[:np.int32(fading_duration*sr)] *= fadein\n",
    "    wav[-np.int32(fading_duration*sr):] *= fadeout\n",
    "    \n",
    "    #insert silence in the track\n",
    "    for (silence_duration, start, stop) in silences_timestamps:\n",
    "        silence = np.zeros(np.int32(silence_duration))\n",
    "        wav[start:stop] *= silence\n",
    "    \n",
    "    return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a213edd-17d1-47f7-ad04-9c3ddf7c66dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Super_Mario_Bros_(NES)_Music_Overworld_Theme 59.0\n",
      "3\n",
      "[180741]\n",
      "[(180741, 390857, 571598)]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 32\u001b[0m\n\u001b[1;32m     27\u001b[0m silenced_wav \u001b[38;5;241m=\u001b[39m insert_silences(wav, sr,silences_timestamps,fading_duration)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(silences_timestamps)\n\u001b[1;32m     29\u001b[0m silence_data \u001b[38;5;241m=\u001b[39m pandas\u001b[38;5;241m.\u001b[39mDataFrame([{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m:category,\n\u001b[1;32m     30\u001b[0m                                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrack\u001b[39m\u001b[38;5;124m'\u001b[39m:file,\n\u001b[1;32m     31\u001b[0m                                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS1_duration\u001b[39m\u001b[38;5;124m'\u001b[39m:silences_timestamps[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS1_start\u001b[39m\u001b[38;5;124m'\u001b[39m:silences_timestamps[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS1_stop\u001b[39m\u001b[38;5;124m'\u001b[39m:silences_timestamps[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m---> 32\u001b[0m                                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS2_duration\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[43msilences_timestamps\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS2_start\u001b[39m\u001b[38;5;124m'\u001b[39m:silences_timestamps[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS2_stop\u001b[39m\u001b[38;5;124m'\u001b[39m:silences_timestamps[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m2\u001b[39m],\n\u001b[1;32m     33\u001b[0m                                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS3_duration\u001b[39m\u001b[38;5;124m'\u001b[39m:silences_timestamps[\u001b[38;5;241m2\u001b[39m][\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS3_start\u001b[39m\u001b[38;5;124m'\u001b[39m:silences_timestamps[\u001b[38;5;241m2\u001b[39m][\u001b[38;5;241m1\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS3_stop\u001b[39m\u001b[38;5;124m'\u001b[39m:silences_timestamps[\u001b[38;5;241m2\u001b[39m][\u001b[38;5;241m2\u001b[39m],\n\u001b[1;32m     34\u001b[0m                                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS4_duration\u001b[39m\u001b[38;5;124m'\u001b[39m:silences_timestamps[\u001b[38;5;241m2\u001b[39m][\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS4_start\u001b[39m\u001b[38;5;124m'\u001b[39m:silences_timestamps[\u001b[38;5;241m2\u001b[39m][\u001b[38;5;241m1\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS4_stop\u001b[39m\u001b[38;5;124m'\u001b[39m:silences_timestamps[\u001b[38;5;241m2\u001b[39m][\u001b[38;5;241m2\u001b[39m],\n\u001b[1;32m     35\u001b[0m                                  }])\n\u001b[1;32m     36\u001b[0m silences_df \u001b[38;5;241m=\u001b[39m pandas\u001b[38;5;241m.\u001b[39mconcat([silences_df, silence_data])\n\u001b[1;32m     39\u001b[0m new_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_silenced\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#define all parameters needed\n",
    "path = '/home/maellef/git/MuteMusic/data/StimuliFinal/long'\n",
    "outpath = \"/home/maellef/git/MuteMusic/data/StimuliFinal/silenced\"\n",
    "\n",
    "fading_duration = 1\n",
    "intro_duration = 5\n",
    "silence_min = 3\n",
    "silence_max = 6\n",
    "silences_nb = [3,4]\n",
    "silence_interval_min = 3\n",
    "\n",
    "silences_df = pandas.DataFrame()\n",
    "\n",
    "for category in os.listdir(path):\n",
    "    for file in os.listdir(os.path.join(path, category)):\n",
    "        name, ext = os.path.splitext(file)\n",
    "        if ext == '.wav':\n",
    "            path_wav=os.path.join(path, category, file)\n",
    "            wav, sr = librosa.load(path_wav, sr=None)\n",
    "            print(name, len(wav)/sr)\n",
    "            silences_timestamps = define_silences_timestamps(start_wav = intro_duration*sr, end_wav=len(wav),\n",
    "                                                             total_wav=len(wav), sr=sr,\n",
    "                                                             percent_silence=0.25, silences_nb=silences_nb,\n",
    "                                                             silence_min=silence_min, silence_max=silence_max, \n",
    "                                                             silence_interval_min=silence_interval_min)\n",
    "            \n",
    "            silenced_wav = insert_silences(wav, sr,silences_timestamps,fading_duration)\n",
    "            print(silences_timestamps)\n",
    "            silence_data = pandas.DataFrame([{'category':category,\n",
    "                                              'track':file,\n",
    "                                              'S1_duration':silences_timestamps[0][0], 'S1_start':silences_timestamps[0][1], 'S1_stop':silences_timestamps[0][2],\n",
    "                                              'S2_duration':silences_timestamps[1][0], 'S2_start':silences_timestamps[1][1], 'S2_stop':silences_timestamps[1][2],\n",
    "                                              'S3_duration':silences_timestamps[2][0], 'S3_start':silences_timestamps[2][1], 'S3_stop':silences_timestamps[2][2],\n",
    "                                              'S4_duration':silences_timestamps[2][0], 'S4_start':silences_timestamps[2][1], 'S4_stop':silences_timestamps[2][2],\n",
    "                                             }])\n",
    "            silences_df = pandas.concat([silences_df, silence_data])\n",
    "            \n",
    "\n",
    "            new_name = f'{name}_silenced{ext}'\n",
    "            new_path = os.path.join(outpath, category)\n",
    "            os.makedirs(new_path, exist_ok=True)\n",
    "            sf.write(file=os.path.join(new_path, new_name), data = silenced_wav, samplerate=sr)\n",
    "\n",
    "output_file= os.path.join(outpath, 'silences_data.tsv')\n",
    "silences_df.to_csv(output_file, sep='\\t', index=False, header=True)\n",
    "print(silences_df)        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
